{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ca0373e",
   "metadata": {},
   "source": [
    "# üß† OpenAI Vector Store Setup\n",
    "Dieses Notebook l√§dt eine Datei hoch, erstellt einen Vector Store, verbindet ihn mit einem Assistant und erm√∂glicht die semantische Suche mit GPT-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7564f4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/philippkemper/Code/openai-vectorstore-assistant/.venv/lib/python3.11/site-packages (1.72.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/philippkemper/Code/openai-vectorstore-assistant/.venv/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/philippkemper/Code/openai-vectorstore-assistant/.venv/lib/python3.11/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/philippkemper/Code/openai-vectorstore-assistant/.venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/philippkemper/Code/openai-vectorstore-assistant/.venv/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/philippkemper/Code/openai-vectorstore-assistant/.venv/lib/python3.11/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/philippkemper/Code/openai-vectorstore-assistant/.venv/lib/python3.11/site-packages (from openai) (2.11.3)\n",
      "Requirement already satisfied: sniffio in /Users/philippkemper/Code/openai-vectorstore-assistant/.venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/philippkemper/Code/openai-vectorstore-assistant/.venv/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/philippkemper/Code/openai-vectorstore-assistant/.venv/lib/python3.11/site-packages (from openai) (4.13.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/philippkemper/Code/openai-vectorstore-assistant/.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/philippkemper/Code/openai-vectorstore-assistant/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/philippkemper/Code/openai-vectorstore-assistant/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/philippkemper/Code/openai-vectorstore-assistant/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/philippkemper/Code/openai-vectorstore-assistant/.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Users/philippkemper/Code/openai-vectorstore-assistant/.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/philippkemper/Code/openai-vectorstore-assistant/.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Installiere notwendige Pakete\n",
    "!pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb886ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîê API-Key einbinden (√ºber .env Datei empfohlen)\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf35af50",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      4\u001b[39m file_path = \u001b[33m\"\u001b[39m\u001b[33mdata/dein_dokument.pdf\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Passe dies an deine Datei an\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m file = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m(file=\u001b[38;5;28mopen\u001b[39m(file_path, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m), purpose=\u001b[33m\"\u001b[39m\u001b[33massistants\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Datei hochgeladen:\u001b[39m\u001b[33m\"\u001b[39m, file.id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/openai-vectorstore-assistant/.venv/lib/python3.13/site-packages/openai/_utils/_proxy.py:20\u001b[39m, in \u001b[36mLazyProxy.__getattr__\u001b[39m\u001b[34m(self, attr)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     proxied = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_proxied__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(proxied, LazyProxy):\n\u001b[32m     22\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m proxied  \u001b[38;5;66;03m# pyright: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/openai-vectorstore-assistant/.venv/lib/python3.13/site-packages/openai/_utils/_proxy.py:55\u001b[39m, in \u001b[36mLazyProxy.__get_proxied__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__get_proxied__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> T:\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__load__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/openai-vectorstore-assistant/.venv/lib/python3.13/site-packages/openai/_module_client.py:24\u001b[39m, in \u001b[36mFilesProxy.__load__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__load__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> resources.Files:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.files\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/openai-vectorstore-assistant/.venv/lib/python3.13/site-packages/openai/__init__.py:329\u001b[39m, in \u001b[36m_load_client\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    313\u001b[39m         _client = _AzureModuleClient(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    314\u001b[39m             api_version=api_version,\n\u001b[32m    315\u001b[39m             azure_endpoint=azure_endpoint,\n\u001b[32m   (...)\u001b[39m\u001b[32m    325\u001b[39m             http_client=http_client,\n\u001b[32m    326\u001b[39m         )\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _client\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     _client = \u001b[43m_ModuleClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43morganization\u001b[49m\u001b[43m=\u001b[49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdefault_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdefault_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _client\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _client\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/openai-vectorstore-assistant/.venv/lib/python3.13/site-packages/openai/_client.py:116\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    114\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    117\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    118\u001b[39m     )\n\u001b[32m    119\u001b[39m \u001b[38;5;28mself\u001b[39m.api_key = api_key\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# üìÅ Datei hochladen\n",
    "from pathlib import Path\n",
    "\n",
    "file_path = \"data/dein_dokument.pdf\"  # Passe dies an deine Datei an\n",
    "file = openai.files.create(file=open(file_path, \"rb\"), purpose=\"assistants\")\n",
    "print(\"‚úÖ Datei hochgeladen:\", file.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c05237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Vector Store erstellen\n",
    "vector_store = openai.beta.vector_stores.create(name=\"Mein Vector Store\")\n",
    "print(\"üìå Vector Store ID:\", vector_store.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1062be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ûï Datei zum Vector Store hinzuf√ºgen\n",
    "openai.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store.id,\n",
    "    files=[file.id]\n",
    ")\n",
    "print(\"‚úÖ Datei im Vector Store gespeichert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bb6abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ü§ñ Assistant erstellen\n",
    "assistant = openai.beta.assistants.create(\n",
    "    name=\"Dokumenten-Helfer\",\n",
    "    instructions=\"Beantworte Fragen basierend auf dem Dokument.\",\n",
    "    tools=[{\"type\": \"retrieval\"}],\n",
    "    model=\"gpt-4\",\n",
    "    vector_store_ids=[vector_store.id],\n",
    ")\n",
    "print(\"üß† Assistant-ID:\", assistant.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d684425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üí¨ Thread starten\n",
    "thread = openai.beta.threads.create()\n",
    "print(\"üí¨ Thread-ID:\", thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba07f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùì Frage stellen und Antwort erhalten\n",
    "def frage_stellen(frage: str):\n",
    "    openai.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=frage,\n",
    "    )\n",
    "    run = openai.beta.threads.runs.create_and_poll(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id,\n",
    "    )\n",
    "    messages = openai.beta.threads.messages.list(thread_id=thread.id)\n",
    "    for msg in reversed(messages.data):\n",
    "        if msg.role == \"assistant\":\n",
    "            return msg.content[0].text.value\n",
    "    return \"Keine Antwort gefunden.\"\n",
    "\n",
    "# Beispiel-Frage:\n",
    "frage_stellen(\"Was steht in Kapitel 3?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a033d09c",
   "metadata": {},
   "source": [
    "üëâ Jetzt kannst du oben deine Datei anpassen und beliebige Fragen stellen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
